{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "import t3f\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Recurrent\n",
    "\n",
    "# First, let's define a RNN Cell, as a layer subclass.\n",
    "\n",
    "class TTMinimalRNNCell(Recurrent):\n",
    "    counter = 0\n",
    "\n",
    "    def __init__(self, row_dims, column_dims, tt_rank=2, init='glorot',\n",
    "                 activation='relu', bias=True, bias_init=0.1, **kwargs):\n",
    "        self.units = np.prod(column_dims)\n",
    "        self.states = [None]\n",
    "        \n",
    "        self.tt_kernel_shape = [row_dims, column_dims]\n",
    "        self.tt_recurrent_shape = [column_dims, column_dims]\n",
    "        self.output_dim = np.prod(column_dims)\n",
    "        self.tt_rank = tt_rank\n",
    "        self.activation = activation\n",
    "        self.bias = bias\n",
    "        self.bias_init = bias_init\n",
    "        self.init = init\n",
    "        \n",
    "        super(TTMinimalRNNCell, self).__init__(**kwargs)        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # kernel\n",
    "        initializer = t3f.glorot_initializer(self.tt_kernel_shape,\n",
    "                                        tt_rank=self.tt_rank)\n",
    "        name = 'tt_rnn_kernel_matrix_{}'.format(TTMinimalRNNCell.counter)\n",
    "        self.kernel = t3f.get_variable(name, initializer=initializer)\n",
    "        \n",
    "        \n",
    "        # recurrent\n",
    "        initializer = t3f.glorot_initializer(self.tt_recurrent_shape,\n",
    "                                        tt_rank=self.tt_rank)\n",
    "        name = 'tt_rnn_recurrent_matrix_{}'.format(TTMinimalRNNCell.counter)\n",
    "        self.recurrent_kernel = t3f.get_variable(name, initializer=initializer)\n",
    "        \n",
    "        self.trainable_weights = list(self.kernel.tt_cores) + list(self.recurrent_kernel.tt_cores)\n",
    "        \n",
    "        TTMinimalRNNCell.counter += 1\n",
    "        self.built = True\n",
    "\n",
    "    def step(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        h = t3f.matmul(inputs, self.kernel)\n",
    "        z = t3f.matmul(prev_output, self.recurrent_kernel)\n",
    "        \n",
    "        output = h + z\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(Flatten(), input_shape=(28, 28)))\n",
    "model.add(TTMinimalRNNCell(row_dims=[4, 7], column_dims=[5, 5], tt_rank=4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_2 (TimeDist (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "tt_minimal_rnn_cell_2 (TTMin (None, 25)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 680\n",
      "Trainable params: 680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train / 127.5 - 1.0\n",
    "x_test = x_test / 127.5 - 1.0\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 55s - loss: 3.1140 - acc: 0.2363 - val_loss: 1.7060 - val_acc: 0.3764\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 53s - loss: 1.3132 - acc: 0.5536 - val_loss: 1.0077 - val_acc: 0.6810\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.9502 - acc: 0.7035 - val_loss: 0.8565 - val_acc: 0.7312\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.8632 - acc: 0.7363 - val_loss: 0.8067 - val_acc: 0.7558\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.8112 - acc: 0.7544 - val_loss: 0.7702 - val_acc: 0.7603\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 53s - loss: 0.7813 - acc: 0.7618 - val_loss: 0.7539 - val_acc: 0.7768\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.7617 - acc: 0.7687 - val_loss: 0.7417 - val_acc: 0.7735\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 49s - loss: 0.7399 - acc: 0.7762 - val_loss: 0.7082 - val_acc: 0.7850\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 52s - loss: 0.7032 - acc: 0.7868 - val_loss: 0.6833 - val_acc: 0.7994\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 49s - loss: 0.6686 - acc: 0.7986 - val_loss: 0.6468 - val_acc: 0.8113\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.6380 - acc: 0.8092 - val_loss: 0.6071 - val_acc: 0.8198\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.6161 - acc: 0.8167 - val_loss: 0.6004 - val_acc: 0.8224\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 49s - loss: 0.6085 - acc: 0.8172 - val_loss: 0.5891 - val_acc: 0.8321\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 53s - loss: 0.5995 - acc: 0.8222 - val_loss: 0.5818 - val_acc: 0.8271\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 53s - loss: 0.5924 - acc: 0.8249 - val_loss: 0.5779 - val_acc: 0.8360\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 53s - loss: 0.5870 - acc: 0.8273 - val_loss: 0.5672 - val_acc: 0.8394\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 53s - loss: 0.5818 - acc: 0.8297 - val_loss: 0.5817 - val_acc: 0.8322\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.5788 - acc: 0.8306 - val_loss: 0.5590 - val_acc: 0.8414\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.5759 - acc: 0.8320 - val_loss: 0.5636 - val_acc: 0.8388\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 53s - loss: 0.5733 - acc: 0.8336 - val_loss: 0.5625 - val_acc: 0.8415\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 61s - loss: 0.5706 - acc: 0.8335 - val_loss: 0.5593 - val_acc: 0.8376\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 60s - loss: 0.5686 - acc: 0.8340 - val_loss: 0.5654 - val_acc: 0.8355\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 56s - loss: 0.5674 - acc: 0.8341 - val_loss: 0.5459 - val_acc: 0.8421\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.5635 - acc: 0.8339 - val_loss: 0.5536 - val_acc: 0.8402\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.5614 - acc: 0.8348 - val_loss: 0.5494 - val_acc: 0.8428\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.5599 - acc: 0.8357 - val_loss: 0.5571 - val_acc: 0.8404\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.5585 - acc: 0.8359 - val_loss: 0.5365 - val_acc: 0.8508\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.5557 - acc: 0.8374 - val_loss: 0.5439 - val_acc: 0.8402\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.5550 - acc: 0.8362 - val_loss: 0.5466 - val_acc: 0.8386\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 49s - loss: 0.5527 - acc: 0.8373 - val_loss: 0.5521 - val_acc: 0.8382\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 48s - loss: 0.5495 - acc: 0.8389 - val_loss: 0.5332 - val_acc: 0.8435\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 57s - loss: 0.5486 - acc: 0.8384 - val_loss: 0.5346 - val_acc: 0.8447\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 60s - loss: 0.5482 - acc: 0.8385 - val_loss: 0.5412 - val_acc: 0.8438\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5475 - acc: 0.8379 - val_loss: 0.5402 - val_acc: 0.8401\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.5448 - acc: 0.8394 - val_loss: 0.5452 - val_acc: 0.8384\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.5442 - acc: 0.8404 - val_loss: 0.5343 - val_acc: 0.8417\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.5420 - acc: 0.8412 - val_loss: 0.5431 - val_acc: 0.8368.\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5443 - acc: 0.8404 - val_loss: 0.5242 - val_acc: 0.8459\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.5422 - acc: 0.8403 - val_loss: 0.5351 - val_acc: 0.8446\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.5402 - acc: 0.8414 - val_loss: 0.5271 - val_acc: 0.8475\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5395 - acc: 0.8427 - val_loss: 0.5238 - val_acc: 0.8449\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.5369 - acc: 0.8423 - val_loss: 0.5188 - val_acc: 0.8484\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.5363 - acc: 0.8423 - val_loss: 0.5431 - val_acc: 0.8403\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5349 - acc: 0.8438 - val_loss: 0.5349 - val_acc: 0.8448\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.5339 - acc: 0.8449 - val_loss: 0.5166 - val_acc: 0.8485\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5299 - acc: 0.8458 - val_loss: 0.5208 - val_acc: 0.8452\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5274 - acc: 0.8458 - val_loss: 0.5194 - val_acc: 0.8540\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 49s - loss: 0.5231 - acc: 0.8471 - val_loss: 0.5240 - val_acc: 0.8505\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5194 - acc: 0.8495 - val_loss: 0.5132 - val_acc: 0.8545\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 49s - loss: 0.5147 - acc: 0.8520 - val_loss: 0.5089 - val_acc: 0.8551\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5100 - acc: 0.8517 - val_loss: 0.4928 - val_acc: 0.8581\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.5041 - acc: 0.8538 - val_loss: 0.5093 - val_acc: 0.8548\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4989 - acc: 0.8561 - val_loss: 0.4812 - val_acc: 0.8600\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4966 - acc: 0.8567 - val_loss: 0.4971 - val_acc: 0.8575\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4923 - acc: 0.8582 - val_loss: 0.4886 - val_acc: 0.8597\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4910 - acc: 0.8588 - val_loss: 0.4774 - val_acc: 0.8602\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4881 - acc: 0.8592 - val_loss: 0.4806 - val_acc: 0.8603\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4857 - acc: 0.8603 - val_loss: 0.4702 - val_acc: 0.8631\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4848 - acc: 0.8598 - val_loss: 0.4785 - val_acc: 0.8632\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.4835 - acc: 0.8597 - val_loss: 0.4784 - val_acc: 0.8611\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.4812 - acc: 0.8611 - val_loss: 0.4680 - val_acc: 0.8663\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4815 - acc: 0.8616 - val_loss: 0.4777 - val_acc: 0.8626\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 50s - loss: 0.4802 - acc: 0.8619 - val_loss: 0.4724 - val_acc: 0.8649\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.4787 - acc: 0.8621 - val_loss: 0.4714 - val_acc: 0.8653\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.4795 - acc: 0.8619 - val_loss: 0.4692 - val_acc: 0.8634\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4784 - acc: 0.8626 - val_loss: 0.4626 - val_acc: 0.8664\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 51s - loss: 0.4754 - acc: 0.8620 - val_loss: 0.4633 - val_acc: 0.8677\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 52s - loss: 0.4745 - acc: 0.8630 - val_loss: 0.4747 - val_acc: 0.8648\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 50s - loss: 0.4755 - acc: 0.8637 - val_loss: 0.4587 - val_acc: 0.8676\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 60s - loss: 0.4739 - acc: 0.8641 - val_loss: 0.4630 - val_acc: 0.8636\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 63s - loss: 0.4726 - acc: 0.8642 - val_loss: 0.4681 - val_acc: 0.8661\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.4712 - acc: 0.8649 - val_loss: 0.4690 - val_acc: 0.8631\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 57s - loss: 0.4709 - acc: 0.8647 - val_loss: 0.4650 - val_acc: 0.8676\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 58s - loss: 0.4709 - acc: 0.8637 - val_loss: 0.4765 - val_acc: 0.8619\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 58s - loss: 0.4706 - acc: 0.8650 - val_loss: 0.4593 - val_acc: 0.8711\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 57s - loss: 0.4691 - acc: 0.8652 - val_loss: 0.4678 - val_acc: 0.8675\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 57s - loss: 0.4675 - acc: 0.8646 - val_loss: 0.4638 - val_acc: 0.8688\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 57s - loss: 0.4665 - acc: 0.8655 - val_loss: 0.4586 - val_acc: 0.8717\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 57s - loss: 0.4662 - acc: 0.8651 - val_loss: 0.4587 - val_acc: 0.8689\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.4646 - acc: 0.8670 - val_loss: 0.4483 - val_acc: 0.8741\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 61s - loss: 0.4610 - acc: 0.8667 - val_loss: 0.4516 - val_acc: 0.8727\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 63s - loss: 0.4573 - acc: 0.8684 - val_loss: 0.4489 - val_acc: 0.8715\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 58s - loss: 0.4530 - acc: 0.8698 - val_loss: 0.4551 - val_acc: 0.8731\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 57s - loss: 0.4451 - acc: 0.8728 - val_loss: 0.4431 - val_acc: 0.8722\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 56s - loss: 0.4401 - acc: 0.8740 - val_loss: 0.4311 - val_acc: 0.8774\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 56s - loss: 0.4391 - acc: 0.8730 - val_loss: 0.4193 - val_acc: 0.8819\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.4343 - acc: 0.8756 - val_loss: 0.4284 - val_acc: 0.8797\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.4336 - acc: 0.8749 - val_loss: 0.4231 - val_acc: 0.8792\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.4309 - acc: 0.8768 - val_loss: 0.4145 - val_acc: 0.8839\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.4303 - acc: 0.8769 - val_loss: 0.4200 - val_acc: 0.8814\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 56s - loss: 0.4288 - acc: 0.8774 - val_loss: 0.4129 - val_acc: 0.8829\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.4283 - acc: 0.8772 - val_loss: 0.4233 - val_acc: 0.8803\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.4291 - acc: 0.8772 - val_loss: 0.4188 - val_acc: 0.8808\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.4267 - acc: 0.8781 - val_loss: 0.4200 - val_acc: 0.8795\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.4268 - acc: 0.8770 - val_loss: 0.4204 - val_acc: 0.8788\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.4270 - acc: 0.8773 - val_loss: 0.4120 - val_acc: 0.8840\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.4239 - acc: 0.8792 - val_loss: 0.4187 - val_acc: 0.8779\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.4245 - acc: 0.8777 - val_loss: 0.4110 - val_acc: 0.8813\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 55s - loss: 0.4231 - acc: 0.8793 - val_loss: 0.4158 - val_acc: 0.8809\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 54s - loss: 0.4234 - acc: 0.8779 - val_loss: 0.4144 - val_acc: 0.8811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80aadbfe48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
